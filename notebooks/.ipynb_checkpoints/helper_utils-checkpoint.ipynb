{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71433d0b",
   "metadata": {},
   "source": [
    "# Helper Utils\n",
    "\n",
    "This notebook contains miscellaneous helper functions that aid various processes in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"imports.ipynb\" #import external libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_contrastive_loss(labels, logits):\n",
    "    \"\"\"\n",
    "    A function defining contrastive loss, used as the loss function for our siamese neural networks.\n",
    "    \n",
    "    Params:\n",
    "        np_array: labels. The true labels for a dataset.\n",
    "        np_array: logits. The predictions of a model for the same dataset.\n",
    "    Returns:\n",
    "        float: loss. The contrastive loss.\n",
    "    \"\"\"\n",
    "    margin = 1\n",
    "    loss = K.mean(labels * K.square(logits) + (1 - labels) * K.square(K.maximum(margin - logits, 0)))\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(predictions, labels,threshold=0.5): # legacy function\n",
    "        return labels[predictions.ravel() < threshold].mean()\n",
    "\n",
    "\n",
    "    \n",
    "def siamese_model_evaluate(model,x,y,threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate a siamese neural network model on a given dataset.\n",
    "    \n",
    "    Params:\n",
    "        tensorflow model: model\n",
    "        np_array: x. The paired dataset.\n",
    "        np_array: y. The dataset's labels.\n",
    "        float: threshold. The decision threshold.\n",
    "    Returns:\n",
    "        float: accuracy.\n",
    "        float: precision.\n",
    "        float: auc. Area under curve.\n",
    "        float: loss.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make predictions\n",
    "    pred = model.predict([x[:, 0], x[:, 1]])\n",
    "\n",
    "    def compute_precision(predictions, labels,threshold=threshold):\n",
    "        # calculate the precision of the model\n",
    "        return labels[predictions.ravel() < threshold].mean()\n",
    "    def compute_accuracy(predictions, labels):\n",
    "        #calculate the accuracy of the model\n",
    "        i = 0\n",
    "        correct = 0\n",
    "        for pred in predictions:\n",
    "            if pred >=0.5:\n",
    "                pred = 0.\n",
    "            else:\n",
    "                pred = 1.\n",
    "            if pred == labels[i]:\n",
    "                correct += 1\n",
    "            i += 1\n",
    "        return correct/i\n",
    "    \n",
    "    def compute_contrastive_loss(y_true, y_pred):\n",
    "        # calculate the contrastive loss\n",
    "        margin = 1\n",
    "        loss = K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "        return loss.numpy()\n",
    "    \n",
    "    precision = compute_precision(pred, y)\n",
    "    if np.isnan(precision):\n",
    "        precision = 0 # if the precision is nan, which can happen with adersarial examples, set to 0\n",
    "    \n",
    "    pred_labels = pred.ravel() < threshold # generate prediction labels\n",
    "    accuracy = accuracy_score(y, pred_labels)\n",
    "    loss = compute_contrastive_loss(y, pred)\n",
    "    auc = roc_auc_score(y,pred_labels)\n",
    "    \n",
    "    return accuracy, precision, auc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b70f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y, preds, margin=1):\n",
    "    \"\"\"\n",
    "    Duplicate function to earlier contrastive loss function.\n",
    "    \"\"\"\n",
    "    # explicitly cast the true class label data type to the predicted\n",
    "    # class label data type (otherwise we run the risk of having two\n",
    "    # separate data types, causing TensorFlow to error out)\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    # calculate the contrastive loss between the true labels and\n",
    "    # the predicted labels\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "    # return the computed contrastive loss to the calling function\n",
    "    return loss\n",
    "\n",
    "def euclidean_distance(vectors):\n",
    "    \"\"\"\n",
    "    Calculate the euclidean distance between two vectors. Used as the similarity metric for our siamese neural networks.\n",
    "    \n",
    "    Params:\n",
    "        list: vectors.\n",
    "    Returns:\n",
    "        float: euclidean distance.\n",
    "    \"\"\"\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca9644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(H, plot_path):\n",
    "    \"\"\" \n",
    "    construct a plot that plots and saves the training history \n",
    "    \"\"\"\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b26b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The following four functions get either the mean accuracy or all accuracy values from a set of evaluations,\n",
    "either for a standard neural network or for a siamese neural network.\"\"\"\n",
    "\n",
    "def get_mean_accuracy(trained_evals): #pass in the evals from attack_model_variations and get the mean accuracy\n",
    "    accs = []\n",
    "    for model_evals in trained_evals:\n",
    "        for evals in model_evals:\n",
    "            accs.append(evals[:][1])\n",
    "    return mean(accs)\n",
    "\n",
    "def get_accuracies(trained_evals):\n",
    "    accs = []\n",
    "    for model_evals in trained_evals:\n",
    "        for evals in model_evals:\n",
    "            accs.append(evals[:][1])\n",
    "    return accs\n",
    "\n",
    "def get_mean_accuracy_siamese(model_evals):\n",
    "    accs = []\n",
    "    for evals in model_evals:\n",
    "        accs.append(evals[1])\n",
    "    return mean(accs)\n",
    "\n",
    "def get_accuracies_siamese(model_evals):\n",
    "    accs = []\n",
    "    for evals in model_evals:\n",
    "        accs.append(evals[1])\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2b4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliffsdelta(x,y):\n",
    "    \"\"\"\n",
    "    We use this function to measure the effect size between our neural networks' accuracies, aiding evaluation. \n",
    "    The function takes two arrays as input and returns a float between -1 and 1.\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    m = len(y)\n",
    "    xy = [(xi,yi) for xi in x for yi in y]\n",
    "    d = sum([1 if xi > yi else -1 if xi < yi else 0 for (xi,yi) in xy]) / (n*m)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09ca540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
