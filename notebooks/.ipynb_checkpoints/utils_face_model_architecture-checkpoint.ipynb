{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596d230d",
   "metadata": {},
   "source": [
    "# Face Classification Model Architecture\n",
    "\n",
    "As the face classification model includes a lambda layer, the model architecture cannot be saved, so must be loaded into the\n",
    "running code in order to load weights, which can be saved, onto it. Therefore, this notebook exists to return the architecture for the face classification model in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4678c341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and utilities, although we will type out our utility functions in full here to make the process clear\n",
    "%run \"utils_imports.ipynb\" # import libraries and helper functions\n",
    "%run \"utils_attacks.ipynb\"\n",
    "%run \"utils_data.ipynb\"\n",
    "%run \"utils_helper.ipynb\"\n",
    "%run \"utils_training.ipynb\"\n",
    "%run \"siamese_attack_variants.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7c914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the get_face_data data_util to get the paired faces dataset\n",
    "X, Y = get_face_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c91b038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ad79aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 46, 1)\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train.shape[2:]\n",
    "img_a = Input(shape=input_dim)\n",
    "img_b = Input(shape=input_dim)\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4835069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding_layer(input_shape): \n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape, name='input_image'),\n",
    "        Conv2D(6, (3,3), data_format='channels_last', activation='relu'), # First block\n",
    "        MaxPooling2D(pool_size=(2,2), padding='same'),\n",
    "        Conv2D(12, (3,3), data_format='channels_last', activation='relu'), # Second block\n",
    "        MaxPooling2D(64, (2,2), padding='same'),\n",
    "        #Conv2D(128, (4,4), activation='relu'), # Third block \n",
    "        #MaxPooling2D(64, (2,2), padding='same'),\n",
    "        #Conv2D(256, (4,4), activation='relu'),# Final embedding block\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "    ], name = 'embedding')\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30eea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "717093f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c89a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e89fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 56, 46, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 56, 46, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " embedding (Sequential)         (None, 128)          200528      ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 1)            0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 200,528\n",
      "Trainable params: 200,528\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_dim, img_a, img_b):\n",
    "    base_network = make_embedding_layer(input_dim)\n",
    "    feat_vecs_a = base_network(img_a)\n",
    "    feat_vecs_b = base_network(img_b)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([feat_vecs_a, feat_vecs_b])\n",
    "    \n",
    "    model = Model(inputs=[img_a, img_b], outputs=distance)\n",
    "    \n",
    "    epochs = 16\n",
    "    rms = RMSprop()\n",
    "    \n",
    "    model.compile(loss=contrastive_loss, optimizer=rms,metrics=[accuracy])\n",
    "    \n",
    "    return model\n",
    "model = make_model(input_dim, img_a, img_b)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f234e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
