{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d5fa51f",
   "metadata": {},
   "source": [
    "# Adversarial Attack variants for siamese neural networks\n",
    "\n",
    "This notebook contains functions to generate adversarial examples specifically to attack siamese neural network image pairs. These variants are based on code from the CleverHans library of popular adversarial attacks and defences https://github.com/cleverhans-lab/cleverhans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04338c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"utils_imports.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f12865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The MomentumIterativeMethod attack.\"\"\"\n",
    "\n",
    "def mim_siamese(\n",
    "    model_fn,\n",
    "    x,\n",
    "    eps=0.3,\n",
    "    eps_iter=0.06,\n",
    "    nb_iter=10,\n",
    "    norm=np.inf,\n",
    "    clip_min=None,\n",
    "    clip_max=None,\n",
    "    y=None,\n",
    "    targeted=False,\n",
    "    decay_factor=1.0,\n",
    "    sanity_checks=True,\n",
    "    multi=True,\n",
    "    loss_fn=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Tensorflow 2.0 implementation of Momentum Iterative Method (Dong et al. 2017).\n",
    "    This method won the first places in NIPS 2017 Non-targeted Adversarial Attacks\n",
    "    and Targeted Adversarial Attacks. The original paper used hard labels\n",
    "    for this attack; no label smoothing.\n",
    "    Paper link: https://arxiv.org/pdf/1710.06081.pdf\n",
    "    :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "    :param x: input tensor.\n",
    "    :param eps: (optional float) maximum distortion of adversarial example\n",
    "              compared to original input\n",
    "    :param eps_iter: (optional float) step size for each attack iteration\n",
    "    :param nb_iter: (optional int) Number of attack iterations.\n",
    "    :param norm: (optional) Order of the norm (mimics Numpy).\n",
    "              Possible values: np.inf, 1 or 2.\n",
    "    :param clip_min: (optional float) Minimum input component value\n",
    "    :param clip_max: (optional float) Maximum input component value\n",
    "    :param y: (optional) Tensor with true labels. If targeted is true, then provide the\n",
    "              target label. Otherwise, only provide this parameter if you'd like to use true\n",
    "              labels when crafting adversarial samples. Otherwise, model predictions are used\n",
    "              as labels to avoid the \"label leaking\" effect (explained in this paper:\n",
    "              https://arxiv.org/abs/1611.01236). Default is None.\n",
    "    :param targeted: (optional) bool. Is the attack targeted or untargeted?\n",
    "              Untargeted, the default, will try to make the label incorrect.\n",
    "              Targeted will instead try to move in the direction of being more like y.\n",
    "    :param decay_factor: (optional) Decay factor for the momentum term.\n",
    "    :param sanity_checks: bool, if True, include asserts (Turn them off to use less runtime /\n",
    "              memory or for unit tests that intentionally pass strange input)\n",
    "    :param multi: (optional) bool, determines whether perturbations are applied to both inputs\n",
    "              in each input pair or not\n",
    "    :param loss_fn: (optional) callable. loss function that takes (labels, logits) as arguments and returns loss.\n",
    "                    default function is 'tf.nn.sparse_softmax_cross_entropy_with_logits'\n",
    "    :return: a tensor for the adversarial example\n",
    "    \"\"\"\n",
    "\n",
    "    if norm == 1:\n",
    "        raise NotImplementedError(\n",
    "            \"This attack hasn't been tested for norm=1.\"\n",
    "            \"It's not clear that FGM makes a good inner \"\n",
    "            \"loop step for iterative optimization since \"\n",
    "            \"it updates just one coordinate at a time.\"\n",
    "        )\n",
    "\n",
    "    # Check if order of the norm is acceptable given current implementation\n",
    "    if norm not in [np.inf, 1, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf, 1, or 2.\")\n",
    "\n",
    "    asserts = []\n",
    "\n",
    "    # If a data range was specified, check that the input was in that range\n",
    "    if clip_min is not None:\n",
    "        asserts.append(tf.math.greater_equal(x, clip_min))\n",
    "\n",
    "    if clip_max is not None:\n",
    "        asserts.append(tf.math.less_equal(x, clip_max))\n",
    "\n",
    "    if y is None:\n",
    "        # Using model predictions as ground truth to avoid label leaking\n",
    "        y = tf.argmax(model_fn(x), 1)\n",
    "    \n",
    "    #cast the y labels as a float tensor\n",
    "    y = tf.cast(y,tf.float32)\n",
    "    \n",
    "    # cast and transpose the input pairs into a format accepted by the function\n",
    "    x11 = x[:, 0]\n",
    "    x22 = x[:, 1]\n",
    "    x1 = tf.cast(x11, tf.float32)\n",
    "    x2 = tf.cast(x22, tf.float32)\n",
    "    x = np.transpose(x, (1,0,2,3,4))\n",
    "    x = tf.cast(x, tf.float32)\n",
    "\n",
    "    # Initialize loop variables\n",
    "    momentum = tf.zeros_like(x)\n",
    "    adv_x = x\n",
    "\n",
    "    i = 0\n",
    "    while i < nb_iter:\n",
    "        # Define gradient of loss wrt input\n",
    "        adv_x_trsp = np.transpose(adv_x, (1,0,2,3,4))\n",
    "        adv_x1 = adv_x_trsp[:,0]\n",
    "        adv_x2 = adv_x_trsp[:,1]\n",
    "        # we convert our list of input pairs into two separate lists and pass them into the compute_gradient function\n",
    "        # we also add our loss function\n",
    "        grad = compute_gradient(model_fn, loss_fn, [adv_x1,adv_x2], y, targeted)\n",
    "        grad = tf.cast(grad, tf.float32)\n",
    "        # Normalize current gradient and add it to the accumulated gradient\n",
    "        red_ind = list(range(1, len(grad.shape)))\n",
    "        avoid_zero_div = tf.cast(1e-12, grad.dtype)\n",
    "        grad = grad / tf.math.maximum(\n",
    "            avoid_zero_div,\n",
    "            tf.math.reduce_mean(tf.math.abs(grad), red_ind, keepdims=True),\n",
    "        )\n",
    "        momentum = decay_factor * momentum + grad\n",
    "\n",
    "        optimal_perturbation = optimize_linear(momentum, eps_iter, norm)\n",
    "        # Update and clip adversarial example in current iteration\n",
    "        adv_x = adv_x + optimal_perturbation # add the perturbations to both images in the input pairs\n",
    "        adv_x = x + clip_eta(adv_x - x, norm, eps)\n",
    "\n",
    "        if clip_min is not None and clip_max is not None:\n",
    "            adv_x = tf.clip_by_value(adv_x, clip_min, clip_max)\n",
    "        i += 1\n",
    "\n",
    "    if sanity_checks:\n",
    "        assert np.all(asserts)\n",
    "\n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The Projected Gradient Descent attack or the Basic Iterative Method attack, depending on whether rand_init is false or true\"\"\"\n",
    "\n",
    "def pgd_siamese(\n",
    "    model_fn,\n",
    "    x,\n",
    "    eps,\n",
    "    eps_iter,\n",
    "    nb_iter,\n",
    "    norm,\n",
    "    loss_fn=None,\n",
    "    clip_min=None,\n",
    "    clip_max=None,\n",
    "    y=None,\n",
    "    targeted=False,\n",
    "    rand_init=None,\n",
    "    rand_minmax=None,\n",
    "    sanity_checks=False,\n",
    "    multi=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    This class implements either the Basic Iterative Method\n",
    "    (Kurakin et al. 2016) when rand_init is set to 0. or the\n",
    "    Madry et al. (2017) method when rand_minmax is larger than 0. This variant of the attack targets pairs of inputs.\n",
    "    Paper link (Kurakin et al. 2016): https://arxiv.org/pdf/1607.02533.pdf\n",
    "    Paper link (Madry et al. 2017): https://arxiv.org/pdf/1706.06083.pdf\n",
    "    :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "    :param x: input tensor.\n",
    "    :param eps: epsilon (input variation parameter); see https://arxiv.org/abs/1412.6572.\n",
    "    :param eps_iter: step size for each attack iteration\n",
    "    :param nb_iter: Number of attack iterations.\n",
    "    :param norm: Order of the norm (mimics NumPy). Possible values: np.inf, 1 or 2.\n",
    "    :param loss_fn: (optional) callable. loss function that takes (labels, logits) as arguments and returns loss.\n",
    "                    default function is 'tf.nn.sparse_softmax_cross_entropy_with_logits'\n",
    "    :param clip_min: (optional) float. Minimum float value for adversarial example components.\n",
    "    :param clip_max: (optional) float. Maximum float value for adversarial example components.\n",
    "    :param y: (optional) Tensor with true labels. If targeted is true, then provide the\n",
    "              target label. Otherwise, only provide this parameter if you'd like to use true\n",
    "              labels when crafting adversarial samples. Otherwise, model predictions are used\n",
    "              as labels to avoid the \"label leaking\" effect (explained in this paper:\n",
    "              https://arxiv.org/abs/1611.01236). Default is None.\n",
    "    :param targeted: (optional) bool. Is the attack targeted or untargeted?\n",
    "              Untargeted, the default, will try to make the label incorrect.\n",
    "              Targeted will instead try to move in the direction of being more like y.\n",
    "    :param rand_init: (optional) float. Start the gradient descent from a point chosen\n",
    "                        uniformly at random in the norm ball of radius\n",
    "                        rand_init_eps\n",
    "    :param rand_minmax: (optional) float. Size of the norm ball from which\n",
    "                        the initial starting point is chosen. Defaults to eps\n",
    "    :param sanity_checks: bool, if True, include asserts (Turn them off to use less runtime /\n",
    "              memory or for unit tests that intentionally pass strange input)\n",
    "    :return: a tensor for the adversarial example\n",
    "    \"\"\"\n",
    "    \n",
    "    #transpose our input pairs into a format accepted by the function\n",
    "    x = np.transpose(x, (1,0,2,3,4))\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    assert eps_iter <= eps, (eps_iter, eps)\n",
    "    if norm == 1:\n",
    "        raise NotImplementedError(\n",
    "            \"It's not clear that FGM is a good inner loop\"\n",
    "            \" step for PGD when norm=1, because norm=1 FGM \"\n",
    "            \" changes only one pixel at a time. We need \"\n",
    "            \" to rigorously test a strong norm=1 PGD \"\n",
    "            \"before enabling this feature.\"\n",
    "        )\n",
    "    if norm not in [np.inf, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf or 2.\")\n",
    "\n",
    "    if loss_fn is None:\n",
    "        loss_fn = tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "\n",
    "    asserts = []\n",
    "\n",
    "    # If a data range was specified, check that the input was in that range\n",
    "    if clip_min is not None:\n",
    "        asserts.append(tf.math.greater_equal(x, clip_min))\n",
    "\n",
    "    if clip_max is not None:\n",
    "        asserts.append(tf.math.less_equal(x, clip_max))\n",
    "\n",
    "    # Initialize loop variables\n",
    "    if rand_minmax is None:\n",
    "        rand_minmax = eps\n",
    "\n",
    "    if rand_init:\n",
    "        eta = random_lp_vector(\n",
    "            tf.shape(x), norm, tf.cast(rand_minmax, x.dtype), dtype=x.dtype\n",
    "        )\n",
    "    else:\n",
    "        eta = tf.zeros_like(x)\n",
    "    \n",
    "    # Clip eta\n",
    "    eta = clip_eta(eta, norm, eps)\n",
    "    adv_x = x + eta\n",
    "    if clip_min is not None or clip_max is not None:\n",
    "        adv_x = tf.clip_by_value(adv_x, clip_min, clip_max)\n",
    "\n",
    "    if y is None:\n",
    "        # Using model predictions as ground truth to avoid label leaking\n",
    "        y = tf.argmax(model_fn(x), 1)\n",
    "\n",
    "    i = 0\n",
    "    while i < nb_iter:\n",
    "        adv_x = fgsm_siamese(\n",
    "            model_fn,\n",
    "            adv_x,\n",
    "            eps_iter,\n",
    "            norm,\n",
    "            loss_fn,\n",
    "            clip_min=clip_min,\n",
    "            clip_max=clip_max,\n",
    "            y=y,\n",
    "            targeted=targeted,\n",
    "            multi=True,\n",
    "            processed=True\n",
    "        )\n",
    "\n",
    "        # Clipping perturbation eta to norm norm ball\n",
    "        eta = adv_x - x\n",
    "        eta = clip_eta(eta, norm, eps)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        adv_x = x + eta\n",
    "\n",
    "        # Redo the clipping.\n",
    "        # FGM already did it, but subtracting and re-adding eta can add some\n",
    "        # small numerical error.\n",
    "        if clip_min is not None or clip_max is not None:\n",
    "            adv_x = tf.clip_by_value(adv_x, clip_min, clip_max)\n",
    "        i += 1\n",
    "    \n",
    "    asserts.append(eps_iter <= eps)\n",
    "    if norm == np.inf and clip_min is not None:\n",
    "        # TODO necessary to cast to x.dtype?\n",
    "        asserts.append(eps + clip_min <= clip_max)\n",
    "\n",
    "    if sanity_checks:\n",
    "        assert np.all(asserts)\n",
    "    return adv_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d80156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The Fast Gradient Sign Method attack\"\"\"\n",
    "\n",
    "def fgsm_siamese(\n",
    "    model_fn,\n",
    "    x,\n",
    "    eps,\n",
    "    norm,\n",
    "    loss_fn=None,\n",
    "    clip_min=None,\n",
    "    clip_max=None,\n",
    "    y=None,\n",
    "    targeted=False,\n",
    "    sanity_checks=False,\n",
    "    multi=True,\n",
    "    processed=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Tensorflow 2.0 implementation of the Fast Gradient Method. This version of the attack targets pairs of inputs.\n",
    "    :param model_fn: a callable that takes an input tensor and returns the model logits.\n",
    "    :param x: input tensor.\n",
    "    :param eps: epsilon (input variation parameter); see https://arxiv.org/abs/1412.6572.\n",
    "    :param norm: Order of the norm (mimics NumPy). Possible values: np.inf, 1 or 2.\n",
    "    :param loss_fn: (optional) callable. Loss function that takes (labels, logits) as arguments and returns loss.\n",
    "                    default function is 'tf.nn.sparse_softmax_cross_entropy_with_logits'\n",
    "    :param clip_min: (optional) float. Minimum float value for adversarial example components.\n",
    "    :param clip_max: (optional) float. Maximum float value for adversarial example components.\n",
    "    :param y: (optional) Tensor with true labels. If targeted is true, then provide the\n",
    "              target label. Otherwise, only provide this parameter if you'd like to use true\n",
    "              labels when crafting adversarial samples. Otherwise, model predictions are used\n",
    "              as labels to avoid the \"label leaking\" effect (explained in this paper:\n",
    "              https://arxiv.org/abs/1611.01236). Default is None.\n",
    "    :param targeted: (optional) bool. Is the attack targeted or untargeted?\n",
    "              Untargeted, the default, will try to make the label incorrect.\n",
    "              Targeted will instead try to move in the direction of being more like y.\n",
    "    :param sanity_checks: bool, if True, include asserts (Turn them off to use less runtime /\n",
    "              memory or for unit tests that intentionally pass strange input)\n",
    "    :param multi: (optional) bool, if False, apply perturbations only to a single input of the input pair.\n",
    "              Otherwise, apply perturbations to both inputs.\n",
    "    :return: a tensor for the adversarial example\n",
    "    \"\"\"\n",
    "    if norm not in [np.inf, 1, 2]:\n",
    "        raise ValueError(\"Norm order must be either np.inf, 1, or 2.\")\n",
    "\n",
    "    if loss_fn is None:\n",
    "        loss_fn = tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "\n",
    "    asserts = []\n",
    "\n",
    "    # If a data range was specified, check that the input was in that range\n",
    "    if clip_min is not None:\n",
    "        asserts.append(tf.math.greater_equal(x, clip_min))\n",
    "\n",
    "    if clip_max is not None:\n",
    "        asserts.append(tf.math.less_equal(x, clip_max))\n",
    "    \n",
    "    #split the input pairs and format them as float32 tensors\n",
    "    x11 = x[:, 0]\n",
    "    x22 = x[:, 1]\n",
    "    x1 = tf.cast(x11, tf.float32)\n",
    "    x2 = tf.cast(x22, tf.float32)\n",
    "    \n",
    "    if processed == False:\n",
    "        x = np.transpose(x, (1,0,2,3,4))\n",
    "    else:\n",
    "        x_trsp = np.transpose(x, (1,0,2,3,4))\n",
    "        x11 = x_trsp[:, 0]\n",
    "        x22 = x_trsp[:, 1]\n",
    "        x1 = tf.cast(x11, tf.float32)\n",
    "        x2 = tf.cast(x22, tf.float32)\n",
    "        \n",
    "    x = tf.cast(x, tf.float32)\n",
    "\n",
    "    if y is None:        \n",
    "        #formatting y labels\n",
    "        y = np.around(model_fn.predict([x1,x2]))\n",
    "        y = np.clip(y,0.,1.)\n",
    "        y = tf.argmax(y,1)\n",
    "    \n",
    "    #y must be cast as float32\n",
    "    y = tf.cast(y,tf.float32)\n",
    "\n",
    "    grad = compute_gradient(model_fn, loss_fn, [x1,x2], y, targeted)\n",
    "\n",
    "    grad = tf.cast(grad, tf.float32)\n",
    "    optimal_perturbation = optimize_linear(grad, eps, norm)\n",
    "    # Add perturbation to original example to obtain adversarial example    \n",
    "    #apply perturbation to the pair\n",
    "    if multi:\n",
    "        adv_x = x + optimal_perturbation #apply perturbations to both inputs in the pair\n",
    "    else:\n",
    "        adv_x = x1 + optimal_perturbation\n",
    "        adv_x = [adv_x[0], x2] #apply perturbations to one input in the pair- this is an experimental feature\n",
    "        adv_x = tf.cast(adv_x, tf.float32)\n",
    "\n",
    "    # If clipping is needed, reset all values outside of [clip_min, clip_max]\n",
    "    if (clip_min is not None) or (clip_max is not None):\n",
    "        # We don't currently support one-sided clipping\n",
    "        assert clip_min is not None and clip_max is not None\n",
    "        adv_x = tf.clip_by_value(adv_x, clip_min, clip_max)\n",
    "\n",
    "    if sanity_checks:\n",
    "        assert np.all(asserts)\n",
    "\n",
    "    return adv_x\n",
    "\n",
    "def process_adversarial_output(adv_x):\n",
    "    \"\"\"\n",
    "    After running our siamese attack variants, we have to transpose the data to return it to its original dimensions\n",
    "    so that it is still accepted by the model it is intended for.\n",
    "    \n",
    "    Params:\n",
    "        list/np_array: adv_x. A list or numpy array of adversarial examples.\n",
    "    Returns:\n",
    "        np_array: adv_x. Return the transposed np_array.\n",
    "    \"\"\"\n",
    "    adv_x = adv_x.numpy()\n",
    "    adv_x = np.transpose(adv_x, (1,0,2,3,4))\n",
    "    return adv_x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
