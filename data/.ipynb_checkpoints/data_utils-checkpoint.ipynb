{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d181977",
   "metadata": {},
   "source": [
    "# Data utilities\n",
    "\n",
    "This notebook contains all helper functions required to generate datasets throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac5f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleverhans\n",
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.attacks.basic_iterative_method import basic_iterative_method\n",
    "from cleverhans.tf2.attacks.madry_et_al import madry_et_al\n",
    "from cleverhans.tf2.attacks.momentum_iterative_method import momentum_iterative_method\n",
    "from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "from cleverhans.tf2.attacks.spsa import spsa\n",
    "from cleverhans.tf2.utils import optimize_linear, compute_gradient, clip_eta, random_lp_vector\n",
    "from numpy.random import default_rng\n",
    "from PIL import Image\n",
    "from scipy.stats import levene, shapiro, mannwhitneyu\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import mean\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, GlobalAveragePooling2D, Input, Lambda, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460171c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get mnist dataset\n",
    "def get_mnist_dataset():\n",
    "    \"\"\"\n",
    "    Retrieves the normalised mnist dataset.\n",
    "    \n",
    "    Returns:\n",
    "        Four np_arrays: mnist_x_train, mnist_x_test, mnist_y_train, mnist_y_test.\n",
    "        The x np_arrays contain images, and y contains image labels.\n",
    "    \"\"\"\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "    (mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
    "    \n",
    "    #normalise the data\n",
    "    mnist_x_train = mnist_x_train / 255.0\n",
    "    mnist_x_test = mnist_x_test / 255.0\n",
    "    \n",
    "    return mnist_x_train, mnist_x_test, mnist_y_train, mnist_y_test\n",
    "\n",
    "def get_traffic_dataset():\n",
    "    \"\"\"\n",
    "    Retrieves the normalised GTSRB dataset in an 80/20 test/train split.\n",
    "    \n",
    "    Returns:\n",
    "        Four np_arrays: traffic_x_train, traffic_x_test, traffic_y_train, traffic_y_test.\n",
    "        The x np_arrays contain images, and y contains image labels.\n",
    "    \"\"\"\n",
    "    cur_path = os.getcwd()\n",
    "    traffic_path = os.path.join(cur_path,'traffic')\n",
    "    traffic_x = []\n",
    "    traffic_y = []\n",
    "    traffic_classes = 43\n",
    "    for i in range(traffic_classes):\n",
    "        path = os.path.join(traffic_path,'Train',str(i))\n",
    "        images = os.listdir(path)\n",
    "        img_num = 0\n",
    "        for a in images:\n",
    "            try:\n",
    "                image = Image.open(path + '\\\\'+ a)\n",
    "                image = image.resize((30,30))\n",
    "                image = np.array(image)\n",
    "                traffic_x.append(image)\n",
    "                traffic_y.append(i)\n",
    "                img_num +=1\n",
    "                if img_num >= 100:\n",
    "                    break\n",
    "            except:\n",
    "                print(\"Error loading image\")\n",
    "\n",
    "    #Converting lists into numpy arrays\n",
    "    traffic_x = np.array(traffic_x)\n",
    "    traffic_y = np.array(traffic_y)\n",
    "    #Splitting training and testing dataset\n",
    "    traffic_x_train, traffic_x_test, traffic_y_train, traffic_y_test = train_test_split(traffic_x, traffic_y, test_size=0.2, random_state=42)\n",
    "    #Converting the labels into one hot encoding\n",
    "    traffic_y_train = to_categorical(traffic_y_train, 43)\n",
    "    traffic_y_test = to_categorical(traffic_y_test, 43)\n",
    "    \n",
    "    #normalising\n",
    "    traffic_x_test = traffic_x_test / 255.0\n",
    "    traffic_x_train = traffic_x_train / 255.0\n",
    "\n",
    "    return traffic_x_train, traffic_x_test, traffic_y_train, traffic_y_test\n",
    "\n",
    "def get_speech_dataset():\n",
    "    \"\"\"\n",
    "    Retrieves the mini speech commands dataset.\n",
    "    \n",
    "    Returns:\n",
    "        Four np_arrays: speech_x_train, speech_x_test, speech_y_train, speech_y_test.\n",
    "        The x np_arrays contain images, and y contains image labels.\n",
    "    \"\"\"\n",
    "    DATASET_PATH = 'mini_speech_commands'\n",
    "\n",
    "    data_dir = pathlib.Path(DATASET_PATH)\n",
    "    if not data_dir.exists():\n",
    "      tf.keras.utils.get_file(\n",
    "          'mini_speech_commands.zip',\n",
    "          origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "          extract=True,\n",
    "          cache_dir='.', cache_subdir='data')\n",
    "\n",
    "    commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "    commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
    "    print('Commands:', commands)\n",
    "\n",
    "    filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "    filenames = tf.random.shuffle(filenames)\n",
    "    num_samples = len(filenames)\n",
    "    print('Number of total examples:', num_samples)\n",
    "    print('Number of examples per label:',\n",
    "          len(tf.io.gfile.listdir(str(data_dir/commands[0]))))\n",
    "    print('Example file tensor:', filenames[0])\n",
    "\n",
    "    train_files = filenames[:6400]\n",
    "    val_files = filenames[6400: 6400 + 800]\n",
    "    test_files = filenames[-800:]\n",
    "\n",
    "    print('Training set size', len(train_files))\n",
    "    print('Validation set size', len(val_files))\n",
    "    print('Test set size', len(test_files))\n",
    "\n",
    "    def decode_audio(audio_binary):\n",
    "      \"\"\"\n",
    "      Decode a binary audio file to a float tensor.\n",
    "      \n",
    "      Params:\n",
    "        audio_binary: binary audio file.\n",
    "      \n",
    "      Return: Float tensor of audio file.\n",
    "      \"\"\"\n",
    "      audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "      return tf.squeeze(audio, axis=-1)\n",
    "\n",
    "    def get_label(file_path):\n",
    "      \"\"\"\n",
    "      Get the label of an audio file.\n",
    "      \n",
    "      Return: audio file as string.\n",
    "      \"\"\"\n",
    "      parts = tf.strings.split(file_path, os.path.sep)\n",
    "\n",
    "      return parts[-2] \n",
    "\n",
    "    def get_waveform_and_label(file_path):\n",
    "      \"\"\"\n",
    "      Get the waveform of an audio file as a float tensor, and the corresponding label\n",
    "      \n",
    "      Params:\n",
    "        String: file_path\n",
    "    \n",
    "      Returns:\n",
    "        Float tensor: waveform.\n",
    "        String: label.\n",
    "      \"\"\"\n",
    "      label = get_label(file_path)\n",
    "      audio_binary = tf.io.read_file(file_path)\n",
    "      waveform = decode_audio(audio_binary)\n",
    "      return waveform, label\n",
    "\n",
    "    #convert audio files into datasets\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(train_files)\n",
    "    waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    def get_spectrogram(waveform):\n",
    "      \"\"\"\n",
    "      Retrieves the spectrogram image of an audio waveform.\n",
    "      \n",
    "      Params:\n",
    "        Float tensor: waveform.\n",
    "    \n",
    "      Returns:\n",
    "        Float tensor: spectrogram.\n",
    "      \"\"\"\n",
    "      # Padding for files with less than 16000 samples\n",
    "      zero_padding = tf.zeros([16000] - tf.shape(waveform), dtype=tf.float32)\n",
    "\n",
    "      # Concatenate audio with padding so that all audio clips will be of the \n",
    "      # same length\n",
    "      waveform = tf.cast(waveform, tf.float32)\n",
    "      equal_length = tf.concat([waveform, zero_padding], 0)\n",
    "      spectrogram = tf.signal.stft(\n",
    "          equal_length, frame_length=255, frame_step=128)\n",
    "\n",
    "      spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "      return spectrogram\n",
    "\n",
    "    def get_spectrogram_and_label_id(audio, label):\n",
    "      \"\"\"\n",
    "      Retrieves the spectrogram image and label of an audio file.\n",
    "      \n",
    "      Params:\n",
    "        Float tensor: audio.\n",
    "        String: label.\n",
    "    \n",
    "      Returns:\n",
    "        Float tensor: spectrogram.\n",
    "        String: label_id.\n",
    "      \"\"\"\n",
    "      spectrogram = get_spectrogram(audio)\n",
    "      spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "      label_id = tf.argmax(label == commands)\n",
    "      return spectrogram, label_id\n",
    "\n",
    "    spectrogram_ds = waveform_ds.map(\n",
    "        get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    def preprocess_dataset(files):\n",
    "      \"\"\"\n",
    "      Convert a set of files into a dataset of spectrogram images and labels.\n",
    "      \n",
    "      Params:\n",
    "        List: files.\n",
    "      \n",
    "      Returns:\n",
    "        List: output_ds.\n",
    "      \"\"\"\n",
    "      files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "      output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "      output_ds = output_ds.map(\n",
    "          get_spectrogram_and_label_id,  num_parallel_calls=AUTOTUNE)\n",
    "      return output_ds\n",
    "\n",
    "    #generate the datasets\n",
    "    train_ds = spectrogram_ds\n",
    "    val_ds = preprocess_dataset(val_files)\n",
    "    test_ds = preprocess_dataset(test_files)\n",
    "\n",
    "    #convert the datasets into our test and train splits\n",
    "    speech_x_test = []\n",
    "    speech_y_test = []\n",
    "\n",
    "    for audio, label in test_ds:\n",
    "      speech_x_test.append(audio.numpy())\n",
    "      speech_y_test.append(label.numpy())\n",
    "\n",
    "    speech_x_test = np.array(speech_x_test)\n",
    "    speech_y_test = np.array(speech_y_test)\n",
    "\n",
    "    speech_x_train = []\n",
    "    speech_y_train = []\n",
    "\n",
    "    for audio, label in train_ds:\n",
    "      speech_x_train.append(audio.numpy())\n",
    "      speech_y_train.append(label.numpy())\n",
    "\n",
    "    speech_x_train = np.array(speech_x_train)\n",
    "    speech_y_train = np.array(speech_y_train)\n",
    "    \n",
    "    return speech_x_train, speech_x_test, speech_y_train, speech_y_test\n",
    "\n",
    "def read_image(filename, byteorder='>'):\n",
    "    \"\"\"\n",
    "    Read an image as a numpy array.\n",
    "    \n",
    "    Params:\n",
    "        String: filename.\n",
    "        String: byteorder.\n",
    "        \n",
    "    Returns:\n",
    "        np_array.\n",
    "    \"\"\"\n",
    "    #open the image\n",
    "    with open(filename, 'rb') as f:\n",
    "        buffer = f.read()\n",
    "    \n",
    "    #extract the header, width, height and maxval\n",
    "    header, width, height, maxval = re.search(\n",
    "        b\"(^P5\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n])*\"\n",
    "        b\"(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\", buffer).groups()\n",
    "    \n",
    "    #convert to numpy array\n",
    "    return np.frombuffer(buffer,\n",
    "                            dtype='u1' if int(maxval) < 256 else byteorder+'u2',\n",
    "                            count=int(width)*int(height),\n",
    "                            offset=len(header)\n",
    "                            ).reshape((int(height), int(width)))\n",
    "\n",
    "def get_face_data(filepath,size=2, total_sample_size=10000):\n",
    "    \"\"\"\n",
    "        Retrieve the face dataset. With default params this will return 20000 image pairs.\n",
    "        \n",
    "        Params:\n",
    "            string: filepath.\n",
    "            int: size.\n",
    "            int: total_sample_size.\n",
    "        Returns:\n",
    "            np_array: X.\n",
    "            np_array: Y.\n",
    "    \"\"\"\n",
    "    #read the image\n",
    "    image = read_image(filepath+'/s' + str(1) + '/' + str(1) + '.pgm', 'rw+')\n",
    "    #reduce the size\n",
    "    image = image[::size, ::size]\n",
    "    #get the new size\n",
    "    dim1 = image.shape[0]\n",
    "    dim2 = image.shape[1]\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    #initialize the numpy array with the shape of [total_sample, no_of_pairs, dim1, dim2]\n",
    "    x_geuine_pair = np.zeros([total_sample_size, 2, dim1, dim2, 1])  # 2 is for pairs\n",
    "    y_genuine = np.zeros([total_sample_size, 1])\n",
    "    \n",
    "    for i in range(40):\n",
    "        for j in range(int(total_sample_size/40)):\n",
    "            ind1 = 0\n",
    "            ind2 = 0\n",
    "            \n",
    "            #read images from same directory (genuine pair)\n",
    "            while ind1 == ind2:\n",
    "                ind1 = np.random.randint(10)\n",
    "                ind2 = np.random.randint(10)\n",
    "            \n",
    "            # read the two images\n",
    "            img1 = read_image('facesatt/s' + str(i+1) + '/' + str(ind1 + 1) + '.pgm', 'rw+')\n",
    "            img2 = read_image('facesatt/s' + str(i+1) + '/' + str(ind2 + 1) + '.pgm', 'rw+')\n",
    "            \n",
    "            #reduce the size\n",
    "            img1 = img1[::size, ::size]\n",
    "            img2 = img2[::size, ::size]\n",
    "            \n",
    "            #store the images to the initialized numpy array\n",
    "            x_geuine_pair[count, 0, :, :, 0] = img1\n",
    "            x_geuine_pair[count, 1, :, :, 0] = img2\n",
    "            \n",
    "            #as we are drawing images from the same directory we assign label as 1. (genuine pair)\n",
    "            y_genuine[count] = 1\n",
    "            count += 1\n",
    "\n",
    "    count = 0\n",
    "    x_imposite_pair = np.zeros([total_sample_size, 2, dim1, dim2, 1])\n",
    "    y_imposite = np.zeros([total_sample_size, 1])\n",
    "    \n",
    "    for i in range(int(total_sample_size/10)):\n",
    "        for j in range(10):\n",
    "            \n",
    "            #read images from different directory (imposite pair)\n",
    "            while True:\n",
    "                ind1 = np.random.randint(40)\n",
    "                ind2 = np.random.randint(40)\n",
    "                if ind1 != ind2:\n",
    "                    break\n",
    "                    \n",
    "            img1 = read_image('facesatt/s' + str(ind1+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
    "            img2 = read_image('facesatt/s' + str(ind2+1) + '/' + str(j + 1) + '.pgm', 'rw+')\n",
    "\n",
    "            img1 = img1[::size, ::size]\n",
    "            img2 = img2[::size, ::size]\n",
    "\n",
    "            x_imposite_pair[count, 0, :, :, 0] = img1\n",
    "            x_imposite_pair[count, 1, :, :, 0] = img2\n",
    "            #as we are drawing images from the different directory we assign label as 0. (imposite pair)\n",
    "            y_imposite[count] = 0\n",
    "            count += 1\n",
    "            \n",
    "    #now, concatenate, genuine pairs and imposite pair to get the whole data\n",
    "    X = np.concatenate([x_geuine_pair, x_imposite_pair], axis=0)/255\n",
    "    Y = np.concatenate([y_genuine, y_imposite], axis=0)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def preprocess_image(image, size):\n",
    "    image = image[::size, ::size]\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1577a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs_1(x, y):\n",
    "  \"\"\"\n",
    "  Make a paired dataset from a given dataset by combining every possible pair.\n",
    "  \n",
    "  Params:\n",
    "      np_array: x.\n",
    "      np_array: y.\n",
    "      \n",
    "  Returns:\n",
    "      np_array: x_pairs.\n",
    "      np_array: y_pairs.\n",
    "  \"\"\"\n",
    "  x_pairs, y_pairs = [], []\n",
    "\n",
    "  tuples = [(x1, y1) for x1, y1 in zip(x, y)]\n",
    "  \n",
    "  for t in itertools.product(tuples, tuples):\n",
    "    pair_A, pair_B = t\n",
    "    img_A, label_A = t[0]\n",
    "    img_B, label_B = t[1]\n",
    "\n",
    "    new_label = int(label_A == label_B)\n",
    "\n",
    "    x_pairs.append([img_A, img_B])\n",
    "    y_pairs.append(new_label)\n",
    "  \n",
    "  x_pairs = np.array(x_pairs)\n",
    "  y_pairs = np.array(y_pairs)\n",
    "\n",
    "  return (x_pairs, y_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e622c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs_2(x, y,multiplier=25):\n",
    "    \"\"\"\n",
    "    Make a paired dataset from a given dataset by generating 25 (multiplier value) positive pairs\n",
    "    and 25 (multiplier value) negative pairs per data point.\n",
    "    \n",
    "    Params:\n",
    "        np_array: x.\n",
    "        np_array: y.\n",
    "        int: multiplier.\n",
    "    \"\"\"\n",
    "    # initialize two empty lists to hold the (image, image) pairs and\n",
    "    # labels to indicate if a pair is positive or negative\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    # calculate the total number of classes present in the dataset\n",
    "    # and then build a list of indexes for each class label that\n",
    "    # provides the indexes for all examples with a given label\n",
    "    num_classes = len(np.unique(y))\n",
    "    idx = [np.where(y == i)[0] for i in range(0, num_classes)]\n",
    "    \n",
    "    for i in range(multiplier): #cycle through this process several times to generate a large dataset\n",
    "        # loop over all images\n",
    "        for idxA in range(len(x)):\n",
    "            # grab the current image and label belonging to the current\n",
    "            # iteration\n",
    "            current_image = x[idxA]\n",
    "            label = y[idxA]\n",
    "            # randomly pick an image that belongs to same class\n",
    "            idxB = np.random.choice(idx[label])\n",
    "            pos_image = x[idxB]\n",
    "            # prepare a positive pair and update the images and labels\n",
    "            pair_images.append([current_image, pos_image])\n",
    "            pair_labels.append([1])\n",
    "            # grab the indices for each of the class labels not equal to\n",
    "            # the current label and randomly pick an image corresponding\n",
    "            # to a label not equal to the current label\n",
    "            neg_idx = np.where(y != label)[0]\n",
    "            neg_image = x[np.random.choice(neg_idx)]\n",
    "            # prepare a negative pair of images and update lists\n",
    "            pair_images.append([current_image, neg_image])\n",
    "            pair_labels.append([0])\n",
    "    # return a 2-tuple of our image pairs and labels\n",
    "    return (np.array(pair_images), np.array(pair_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d9129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_sample(x,y,size=400):\n",
    "    \"\"\"\n",
    "    Get a small sample of a given dataset, ensuring that all classes are represented at least once.\n",
    "    \n",
    "    Params:\n",
    "        np_array: x.\n",
    "        np_array: y.\n",
    "        int: size. The size of the dataset that will be returned\n",
    "        \n",
    "    Returns:\n",
    "        np_array: x[all_indices]. The random sample of x values.\n",
    "        np_array: y[all_indices]. The corresponding y values.\n",
    "    \"\"\"\n",
    "    unique_labels = np.unique(y)\n",
    "    \n",
    "    selected_indices = []\n",
    "    #select one data item for each label, ensuring that all classes are represented at least once in the sample\n",
    "    for label in unique_labels:\n",
    "            found = False\n",
    "            while found == False:\n",
    "                for i in range(len(x)):\n",
    "                    if y[i] == label:\n",
    "                        selected_indices.append(i)\n",
    "                        found = True\n",
    "                        break\n",
    "    random_indices = np.random.choice(x.shape[0],size-len(unique_labels),replace=False)\n",
    "    \n",
    "    all_indices = np.concatenate((selected_indices,random_indices))\n",
    "    \n",
    "\n",
    "    return x[all_indices], y[all_indices]\n",
    "\n",
    "def get_siamese_dataset(x,y,expand_dims=True, size=400, one_hot=False,dataset_style=2):\n",
    "    \"\"\"\n",
    "    Get a paired dataset from a given dataset.\n",
    "    \n",
    "    Params:\n",
    "        np_array: x.\n",
    "        np_array: y.\n",
    "        bool: expand_dims. If the x values require an extra dimension this is true (like for MNIST).\n",
    "        int: size. The size of the dataset.\n",
    "        bool: one_hot. True if the y labels are one-hot encoded.\n",
    "        int: dataset_style. 1 for unbalanced dataset, 2 for balanced dataset.\n",
    "        \n",
    "    Returns:\n",
    "        (np_array, np_array): (x_siamese, y_siamese). The siamese paired dataset.\n",
    "    \"\"\"\n",
    "    if one_hot:\n",
    "        y = np.where(y==1)[1]\n",
    "    \n",
    "    x_sample, y_sample = get_dataset_sample(x,y, size=size)\n",
    "    \n",
    "    if expand_dims:\n",
    "        x_sample = np.expand_dims(x_sample, axis=-1)\n",
    "    \n",
    "    if dataset_style == 1:\n",
    "        (x_siamese, y_siamese) = make_pairs_1(x_sample,y_sample)\n",
    "    else:\n",
    "        (x_siamese, y_siamese) = make_pairs_2(x_sample,y_sample,multiplier=25)\n",
    "    \n",
    "    return (x_siamese, y_siamese)\n",
    "\n",
    "def resize_data(x,np_array=True): #for resizing speech images to 32x32\n",
    "    \"\"\"\n",
    "    This function is built to resize speech dataset images down to 32x32.\n",
    "    \n",
    "    Params:\n",
    "        np_array: x.\n",
    "        bool: np_array. True if the user wishes for the return value to be an np_array. Otherwise a list is returned.\n",
    "    \n",
    "    Returns:\n",
    "        np_array or list: x_resized.\n",
    "    \"\"\"\n",
    "    x_copy = x.copy()\n",
    "    x_resized = []\n",
    "    for img in x_copy:\n",
    "        img = cv2.resize(img, dsize=(32, 32), interpolation=cv2.INTER_LINEAR)\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        x_resized.append(img)\n",
    "    \n",
    "    if np_array:\n",
    "        x_resized = np.asarray(x_resized)\n",
    "    return x_resized\n",
    "\n",
    "def get_siamese_datasets(train_datasets,test_datasets,expand_dims=False, one_hot=False,dataset_style=2,size=400):\n",
    "    \"\"\"\n",
    "    Takes a set of adversarial datasets and converts them into siamese paired datasets.\n",
    "    \n",
    "    Params:\n",
    "        list: train_datasets. List of pairs of np_arrays for each dataset.\n",
    "        list: test_datasets. List of pairs of np_arrays for each dataset.\n",
    "        bool: expand_dims. True if image dimensions need expanding (MNIST).\n",
    "        bool: one_hot. True if y labels are one-hot encoded (traffic).\n",
    "        int: dataset_style. 1 to generate unbalanced dataset, 2 for balanced dataset.\n",
    "        int: size. How many data points should be in the siamese dataset.\n",
    "        \n",
    "    Returns:\n",
    "        list: siamese_train_datasets. List of pairs of np_arrays for each dataset.\n",
    "        list: siamese_test_datasets. List of pairs of np_arrays for each dataset.\n",
    "    \"\"\"\n",
    "    siamese_train_datasets = []\n",
    "    siamese_test_datasets = []\n",
    "    \n",
    "    (x_train_siamese_fgsm, y_train_siamese_fgsm) = get_siamese_dataset(train_datasets[0][0],train_datasets[0][1], expand_dims=expand_dims, one_hot=one_hot, size=size, dataset_style=dataset_style)\n",
    "    (x_test_siamese_fgsm, y_test_siamese_fgsm) = get_siamese_dataset(test_datasets[0][0],test_datasets[0][1], expand_dims=expand_dims, one_hot=one_hot, size=int(size/2), dataset_style=dataset_style)\n",
    "    siamese_train_datasets.append([x_train_siamese_fgsm, y_train_siamese_fgsm])\n",
    "    siamese_test_datasets.append([x_test_siamese_fgsm,y_test_siamese_fgsm])\n",
    "    \n",
    "    (x_train_siamese_bim, y_train_siamese_bim) = get_siamese_dataset(train_datasets[1][0],train_datasets[1][1], expand_dims=expand_dims, one_hot=one_hot, size=size, dataset_style=dataset_style)\n",
    "    (x_test_siamese_bim, y_test_siamese_bim) = get_siamese_dataset(test_datasets[1][0],test_datasets[1][1], expand_dims=expand_dims, one_hot=one_hot, size=int(size/2), dataset_style=dataset_style)\n",
    "    siamese_train_datasets.append([x_train_siamese_bim, y_train_siamese_bim])\n",
    "    siamese_test_datasets.append([x_test_siamese_bim,y_test_siamese_bim])\n",
    "    \n",
    "    (x_train_siamese_pgd, y_train_siamese_pgd) = get_siamese_dataset(train_datasets[2][0],train_datasets[2][1], expand_dims=expand_dims, one_hot=one_hot, size=size, dataset_style=dataset_style)\n",
    "    (x_test_siamese_pgd, y_test_siamese_pgd) = get_siamese_dataset(test_datasets[2][0],test_datasets[2][1], expand_dims=expand_dims, one_hot=one_hot, size=int(size/2), dataset_style=dataset_style)\n",
    "    siamese_train_datasets.append([x_train_siamese_pgd, y_train_siamese_pgd])\n",
    "    siamese_test_datasets.append([x_test_siamese_pgd,y_test_siamese_pgd])\n",
    "    \n",
    "    (x_train_siamese_mim, y_train_siamese_mim) = get_siamese_dataset(train_datasets[3][0],train_datasets[3][1], expand_dims=expand_dims, one_hot=one_hot, size=size, dataset_style=dataset_style)\n",
    "    (x_test_siamese_mim, y_test_siamese_mim) = get_siamese_dataset(test_datasets[3][0],test_datasets[3][1], expand_dims=expand_dims, one_hot=one_hot, size=int(size/2), dataset_style=dataset_style)\n",
    "    siamese_train_datasets.append([x_train_siamese_mim, y_train_siamese_mim])\n",
    "    siamese_test_datasets.append([x_test_siamese_mim,y_test_siamese_mim])\n",
    "    \n",
    "    return siamese_train_datasets,siamese_test_datasets\n",
    "\n",
    "def save_dataset(dataset,filename):\n",
    "    \"\"\"\n",
    "    Save a dataset.\n",
    "        \n",
    "    Params:\n",
    "        list: dataset. List containing two numpy arrays, one for x and one for y data.\n",
    "        string: filename. The name of the file the dataset will be saved as.\n",
    "    \"\"\"\n",
    "    with open (str(filename)+'.pkl','wb') as f:\n",
    "        pickle.dump(dataset,f)\n",
    "        \n",
    "def load_dataset(filename):\n",
    "    \"\"\"\n",
    "    Load a saved dataset.\n",
    "    \n",
    "    Params:\n",
    "        string: filename. The name of the dataset to load.\n",
    "        \n",
    "    Returns:\n",
    "        pickle.load: f. The loaded file.\n",
    "        int: 0. Returns this if there has been a loading error.\n",
    "    \"\"\"\n",
    "    with open (str(filename)+'.pkl','rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "    #return 0 if error\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699082a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a00251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
